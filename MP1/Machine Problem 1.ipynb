{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgOlLnxFjoeN"
      },
      "source": [
        "# Machine Problem 1\n",
        "#### DIGIMAP S13 Group 3 Bon, Jawali, Lopez, O'Neil, Rejano\n",
        "## Affine Transformations\n",
        "### Directions\n",
        "The goal of the machine problem is to apply the concepts of affine transformations, specifically using geometric transformations. You are to submit two files for this activity: (1) a Jupyter notebook containing the solutions to the action items. Ensure you provide comments, discussions, and proper section divisions for your code. Please also include your answer to the Guide Questions in the Jupyter Notebook; (2) a PDF version of your Jupyter Notebook. You can provide a link to your submission resources or a zip file. The instructor will run it on their local machine, so make sure the codes and files are accessible and functional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vV5ZWYXIjoeQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ZXOA5NjoeS"
      },
      "source": [
        "#### [Data Formatting] Given the image dataset:\n",
        "* Reshape the images to (100,100,3)\n",
        "* Save the transformed images as JPEG files in a separate directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5WRLkAngjoeS"
      },
      "outputs": [],
      "source": [
        "input_directory = '../media/dataset2'\n",
        "output_directory = 'dataset2_resized'\n",
        "\n",
        "if not os.path.exists(output_directory): # creates directory if it does not exist\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
        "        img_path = os.path.join(input_directory, filename)\n",
        "        img = cv.imread(img_path)\n",
        "\n",
        "        # resize the image to 100x100 pixels\n",
        "        img_resized = cv.resize(img, (100, 100))\n",
        "\n",
        "        # save the resized image as JPEG in a separate directory\n",
        "        output_filename = os.path.join(output_directory, filename)\n",
        "        cv.imwrite(output_filename, img_resized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3fndUrWjoeT"
      },
      "source": [
        "#### [Data Augmentation] Given the previous dataset:\n",
        "* Create individual parametrized functions that can:\n",
        "* Randomly put a black patch over a portion of the image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YG7ck7OzjoeT"
      },
      "outputs": [],
      "source": [
        "def random_black_patch(img):\n",
        "    h, w, _ = img.shape\n",
        "    patch_size = np.random.randint(10, 30) # randomly selects the size of the black patch, currently set between 10 to 30 pixels\n",
        "    x1 = np.random.randint(0, w - patch_size) \n",
        "    y1 = np.random.randint(0, h - patch_size)\n",
        "    img[y1:y1+patch_size, x1:x1+patch_size] = 0 # sets the pixels in the selected area to black\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLi0f44djoeU"
      },
      "source": [
        "* Shift an image sideward or upwards.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "skcJ0qz_joeU"
      },
      "outputs": [],
      "source": [
        "def shift_image(img, shift_x, shift_y):\n",
        "    h, w = img.shape[:2]\n",
        "    \n",
        "    # creates a transformation matrix for shifting\n",
        "    # [1, 0, shift_x] shifts the image by 'shift_x' pixels horizontally\n",
        "    # [0, 1, shift_y] shifts the image by 'shift_y' pixels vertically\n",
        "    M = np.float32([[1, 0, shift_x], [0, 1, shift_y]]) \n",
        "    shifted_img = cv.warpAffine(img, M, (w, h)) # apply the shifting using the affine transformation\n",
        "    return shifted_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd5JOBuKjoeV"
      },
      "source": [
        "* Rotate an image either for"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZqCVb6MkjoeV"
      },
      "outputs": [],
      "source": [
        "def rotate_image(img, angle):\n",
        "    h, w = img.shape[:2]\n",
        "    center = (w // 2, h // 2) # determines the center of the image\n",
        "    M = cv.getRotationMatrix2D(center, angle, 1.0) # positive angle -> counter clockwise rotation, negative angle -> clockwise rotation\n",
        "    rotated_img = cv.warpAffine(img, M, (w, h)) # apply the rotation using the affine transformation\n",
        "    return rotated_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaU7NmHljoeV"
      },
      "source": [
        "* Flip an image either vertically or horizontally.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vl0S7LU-joeV"
      },
      "outputs": [],
      "source": [
        "def flip_image(image, value):\n",
        "    return cv.flip(image, value)  # 0 -> vertical, 1 -> horizontal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvdsS5wJjoeW"
      },
      "source": [
        "#### Produce a new augmented dataset with at least 100 images (original images included) using the functions made in the previous action item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xw9icTQdjoeW"
      },
      "outputs": [],
      "source": [
        "augmented_output_dir = 'dataset2_augmented'\n",
        "if not os.path.exists(augmented_output_dir): # creates directory if does not exist\n",
        "    os.makedirs(augmented_output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aQmp-rn1joeW"
      },
      "outputs": [],
      "source": [
        "def combine_augmentations(image, aug_func1, aug_func2):\n",
        "    # apply the first augmentation\n",
        "    img_aug1 = aug_func1(image.copy())\n",
        "    # apply the second augmentation\n",
        "    img_aug2 = aug_func2(img_aug1)\n",
        "    return img_aug2\n",
        "\n",
        "image_count = 0\n",
        "augmentations = [\n",
        "    (random_black_patch, 'random_black_patch'),\n",
        "    (lambda img: shift_image(img, 20, 0), 'shift_right_20px'),\n",
        "    (lambda img: shift_image(img, 0, -20), 'shift_up_20px'),\n",
        "    (lambda img: rotate_image(img, 45), 'rotate_45_degrees'),\n",
        "    (lambda img: flip_image(img, 0), 'flip_vertically'),\n",
        "    (lambda img: flip_image(img, 1), 'flip_horizontally'),\n",
        "]\n",
        "\n",
        "for filename in os.listdir(output_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        img_path = os.path.join(output_directory, filename)\n",
        "        image = cv.imread(img_path)\n",
        "\n",
        "        # saving the original resized image\n",
        "        cv.imwrite(os.path.join(augmented_output_dir, filename), image)\n",
        "        image_count += 1\n",
        "\n",
        "        # saving the augmented images \n",
        "        for i in range(len(augmentations)):\n",
        "            # single augmentations\n",
        "            aug_func, aug_desc = augmentations[i]\n",
        "            output_filename = f'{filename.split(\".\")[0]}_{aug_desc}.jpg'\n",
        "            cv.imwrite(os.path.join(augmented_output_dir, output_filename), aug_func(image.copy()))\n",
        "            image_count += 1\n",
        "            \n",
        "            # combine augmentations \n",
        "            for j in range(i + 1, len(augmentations)):\n",
        "                aug_func2, aug_desc2 = augmentations[j]\n",
        "                combined_image = combine_augmentations(image, aug_func, aug_func2)\n",
        "                output_filename_combined = f'{filename.split(\".\")[0]}_{aug_desc}_{aug_desc2}.jpg'\n",
        "                cv.imwrite(os.path.join(augmented_output_dir, output_filename_combined), combined_image)\n",
        "                image_count += 1\n",
        "            \n",
        "            if image_count >= 150:  # stop if already reached 150 images\n",
        "                break\n",
        "\n",
        "    if image_count >= 150:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV0hm0TSjoeW"
      },
      "source": [
        "### Guide Questions:\n",
        "**1. Define Data Augmentation and discuss its importance and the importance of understanding digital image processing for such an activity.**\n",
        "\n",
        "Data augmentation refers to techniques used in artificially expanding a dataset by creating modified versions of existing data. In digital image processing, it involves applying transformations, such as rotation, scaling, flipping, cropping, and many more, to generate new images from the original ones. \n",
        "\n",
        "The altered version of such images enhance machine learning model performance by increasing the size and diversity of the training set. This process acts as a form of regularization as it introduces noise into the data and helps prevent overfitting.  This also provides a cost-effective approach to maximizing the utility of existing data since it reduces the time and expense involved in acquiring and annotating large datasets, making it an efficient solution for enhanced model training.\n",
        "\n",
        "A good understanding of digital image processing is key to applying data augmentation effectively, since it allows the appropriate selection of augmentation techniques based on the characteristics of the data and the goals of the model. By ensuring that transformations, such as geometric alterations or color adjustments, are applied appropriately, the augmented data retains its relevance and realism.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shbYP79-joeX"
      },
      "source": [
        "\n",
        "**2. What other data augmentation techniques are applicable and not applicable to the dataset you have produced? Why?**\n",
        "\n",
        "Scaling, brightness adjustment, and adding noise are other applicable data augmentation techniques for this dataset. First, scaling the image by zooming in or out can provide variations in size and context, helping models recognize objects at different scales. Second, brightness adjustment simulates different lighting conditions, allowing the model to handle variations in exposure. Third, adding noise introduces random distortions, which can improve the model's robustness to imperfections in real-world data. \n",
        "\n",
        "However, some techniques may not be as applicable. For example, convolution applies filters to highlight edges or textures and is better suited for feature extraction or pre-processing. It also alters the image by emphasizing specific features such as edges, patterns, or textures, which may not add the kind of variability needed for data augmentation. Instead of diversifying the dataset, it risks making the model too focused on certain image characteristics, potentially leading to reduced generalization. Similarly, shearing, which skews the image along the x or y axis, may distort the overall structure and integrity of objects in the image, making them less recognizable. Shearing can result in unrealistic transformations that might confuse the model, especially if the objects being recognized rely on a more accurate spatial relationship. Therefore, while some augmentations like scaling and brightness adjustment help improve model generalization, convolution and shearing could introduce distortions that aren't as beneficial for creating varied, yet realistic, training data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
