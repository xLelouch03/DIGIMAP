{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Animal Classification using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Animal-10 Dataset\n",
    "\n",
    "The Animals-10 Dataset contains approximately 28,000 medium-quality images categorized into 10 classes: dog, cat, horse, spider, butterfly, chicken, sheep, cow, squirrel, and elephant. These images were collected from Google Images and verified by humans, with some erroneous samples included to reflect real-world conditions, such as user-submitted images.\n",
    "\n",
    "The dataset is organized into directories corresponding to each category, with class sizes ranging from 2,000 to 5,000 images. This dataset can simulate applications such as smart image galleries for researchers like biologists.\n",
    "\n",
    "This dataset was downloaded from Kaggle and was submitted by Corrado Alessio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing and Splitting Dataset \n",
    "\n",
    "First, we define a manual transformation pipeline, which resizes images to 224x224 pixels and converts them to tensors. The dataset is loaded using ImageFolder with the defined transformation applied. The dataset is then split into three subsets: training, testing, and validation. An 80-20 split is first applied to separate the training set from a combined test and validation set. This combined set is further divided into two equal parts for testing and validation. This setup ensures the dataset is properly preprocessed and divided for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname('MCO')  \n",
    "dataset_path = os.path.join(base_dir, 'archive', 'raw-img')\n",
    "\n",
    "dataset = ImageFolder(root=dataset_path, transform=manual_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataset \n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_val_size = len(dataset) - train_size\n",
    "train_data, test_val_data = random_split(dataset, [train_size, test_val_size])\n",
    "\n",
    "# Create test and validation set from test_val_dataset\n",
    "test_size = int(0.5 * len(test_val_data))\n",
    "val_size = len(test_val_data) - test_size\n",
    "test_data, val_data = random_split(test_val_data, [test_size, val_size])\n",
    "\n",
    "# Check the len of the train, test, val dataset\n",
    "len(train_data), len(test_data), len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Pre-trained EfficientNet-B0 with Data Transformations\n",
    "\n",
    "This code sets up a pre-trained EfficientNet-B0 model using PyTorch's torchvision library. It loads default weights optimized on a large dataset (like ImageNet), prepares the model for the specified device (CPU or GPU), and retrieves the recommended data preprocessing steps (like resizing and normalization) that match the model's training. These transformations ensure the input data is properly formatted for accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset with Pretrained Transformations\n",
    "\n",
    "Earlier, we did manual_transform which provided the basic preprocessing we defined relating to image size. Now, we will also apply auto_transform which was predefined and tailored to the selected pre-trained model (EfficientNet). \n",
    "\n",
    "In this case, as shown above, the images are resized so that their shorter edge is 256 pixels while maintaining the aspect ratio. They are then cropped to a fixed size of 224x224 pixels to match the input dimensions expected by the model.  Bicubic interpolation is used during resizing, which provides smooth and high-quality image scaling. \n",
    "\n",
    "The images are also normalized using mean values [0.485, 0.456, 0.406] and standard deviations [0.229, 0.224, 0.225] for the red, green, and blue channels, respectively. This normalization ensures the pixel values are scaled and centered around zero with a standard deviation of one, consistent with the dataset (e.g., ImageNet) on which the model was originally trained. These steps collectively ensure compatibility with the model and optimize its performance.\n",
    "\n",
    "The dataset is then split into three subsets: training, testing, and validation. An 80-20 split is first applied to separate the training set from a combined test and validation set. This combined set is further divided into two equal parts for testing and validation. This setup ensures the dataset is properly preprocessed and divided for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname('MCO')  \n",
    "dataset_path = os.path.join(base_dir, 'archive', 'raw-img')\n",
    "\n",
    "dataset = ImageFolder(root=dataset_path, transform=auto_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_val_size = len(dataset) - train_size\n",
    "train_dataset, test_val_dataset = random_split(dataset, [train_size, test_val_size])\n",
    "\n",
    "# Create test and validation set from test_val_dataset\n",
    "test_size = int(0.5 * len(test_val_dataset))\n",
    "val_size = len(test_val_dataset) - test_size\n",
    "test_dataset, val_dataset = random_split(test_val_dataset, [test_size, val_size])\n",
    "\n",
    "# Check the len of the train, test, val dataset\n",
    "len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataLoaders\n",
    " In this stage, data loaders for training, testing, and validation datasets are created. This enables efficient data batching, shuffling, and parallel data loading during training or evaluation. \n",
    " \n",
    " The lengths of the data loaders indicate the number of batches in each dataset, which are (655, 82, 82) for train_loader, test_loader, and val_loader respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=2)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       shuffle=False,\n",
    "                       num_workers=2)\n",
    "\n",
    "len(train_loader), len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = {\n",
    "    \"cane\": \"dog\", \n",
    "    \"cavallo\": \"horse\", \n",
    "    \"elefante\": \"elephant\", \n",
    "    \"farfalla\": \"butterfly\", \n",
    "    \"gallina\": \"chicken\", \n",
    "    \"gatto\": \"cat\", \n",
    "    \"mucca\": \"cow\", \n",
    "    \"pecora\": \"sheep\", \n",
    "    \"scoiattolo\": \"squirrel\", \n",
    "    \"ragno\": \"spider\",\n",
    "    \"dog\": \"cane\", \n",
    "    \"elephant\": \"elefante\", \n",
    "    \"butterfly\": \"farfalla\", \n",
    "    \"chicken\": \"gallina\", \n",
    "    \"cat\": \"gatto\", \n",
    "    \"cow\": \"mucca\", \n",
    "    \"spider\": \"ragno\", \n",
    "    \"squirrel\": \"scoiattolo\"\n",
    "}\n",
    "\n",
    "english_class_names = [translate[class_name] for class_name in class_names]\n",
    "english_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_dataset), size=[1]).item()\n",
    "    img, label = train_dataset[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.permute(2, 1, 0))\n",
    "    plt.title(english_class_names[label])\n",
    "    plt.axis(False); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below freezes the base feature extractor. This prevents updates to these layers during training, ensuring only the newly added classifier layers are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random number generators for both the CPU (torch.manual_seed) and GPU (torch.cuda.manual_seed) are seeded with the value 42 to ensure reproducibility of results by controlling the randomness in weight initialization and other stochastic processes.\n",
    "\n",
    "The number of output units for the new classifier layer is determined based on the length of class_names, which corresponds to the number of target classes in the dataset.\n",
    "\n",
    "The classifier section of the model is replaced with a new sequential layer. \n",
    "\n",
    "It includes:\n",
    "- A Dropout layer with a dropout probability of 0.2 to help prevent overfitting.\n",
    "- A Linear layer with 1280 input features and output_shape output units, where output_shape matches the number of classes. This layer is moved to the specified device (to(device)), such as a CPU or GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "output_shape = len(class_names)\n",
    "\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True), \n",
    "    torch.nn.Linear(in_features=1280, \n",
    "                    out_features=output_shape,\n",
    "                    bias=True)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224), \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss and Optimizer\n",
    "\n",
    "The selected loss function is Cross-Entropy Loss since it is suitable for multi-class classification problems where each input belongs to exactly one of the classes. It measures the difference between the predicted class probabilities (output from the model) and the true class labels.\n",
    "\n",
    "The selected optimizer is Adam optimizer, a widely used optimization algorithm combining the benefits of both momentum-based optimization and adaptive learning rates. The learning rate is set to 0.001 which controls how much the model's weights are adjusted in response to the computed gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from going_modular.going_modular import data_setup, engine\n",
    "except:\n",
    "    # Get the going_modular scripts\n",
    "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    !mv pytorch-deep-learning/going_modular .\n",
    "    !rm -rf pytorch-deep-learning\n",
    "    from going_modular.going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing the Model\n",
    "\n",
    "Here, we set the random seed for reproducibility. A PyTorch model for 5 epochs using a training and validation dataset, Adam optimizer, and Cross Entropy Loss is trained. We also measure and print the total training time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
